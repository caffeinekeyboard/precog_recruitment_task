{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bcdc473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Tuple, Literal, List\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
    "from wonderwords import RandomWord\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13edc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_captcha(text, captcha_type: str = \"easy\", min_width: int = 512, height: int=224) -> Tuple[Image.Image, str]:\n",
    "    \"\"\"\n",
    "    Generates a text-based CAPTCHA image.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to be included in the CAPTCHA.\n",
    "        captcha_type (str): The type of CAPTCHA to generate (\"easy\", \"hard\", \"bonus\").\n",
    "        min_width (int): Minimum width of the CAPTCHA image.\n",
    "        height (int): Height of the CAPTCHA image.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[Image.Image, str]: A tuple containing the CAPTCHA image and the text.\n",
    "    \n",
    "    Easy CAPTCHA: Renders text in Arial font in the center of a white background. \n",
    "\n",
    "    Hard CAPTCHA: Renders text in a random font in the center of a random background, adds the following distortions:\n",
    "        - Random background color ((r, g, b) where each is differently in [200-255])\n",
    "        - Random font color ((r, g, b) where each is differently in [0-100])\n",
    "        - Random font size in [50%-70%] of image height\n",
    "        - 5% rainbow noise\n",
    "        - Gaussian blur with radius 0.5 pixels\n",
    "        \n",
    "    Bonus CAPTCHA: Renders text in a random font in the center of a random background, and follows the Hard CAPTCHA distortions in addition to:\n",
    "        - Randomly mirrors the text horizontally with 50% probability.\n",
    "        - If the text is mirrored, background color is red, else green.\n",
    "    \"\"\"\n",
    "    font_height = 156 if captcha_type == \"easy\" else (random.randint(int(0.5 * height), int(0.7 * height)))\n",
    "    font_face = \"fonts/arial.ttf\" if captcha_type == \"easy\" else \"fonts/\" + random.choice(os.listdir(\"fonts\")) \n",
    "    font = ImageFont.truetype(font_face, font_height)\n",
    "    text_length = font.getlength(text)\n",
    "    width = int(max(min_width, text_length + 80))\n",
    "    if captcha_type == \"easy\":\n",
    "        image = Image.new(\"RGB\", (width, height), (255, 255, 255))\n",
    "    elif captcha_type == \"hard\":\n",
    "        image = Image.new(\"RGB\", (width, height),(random.randint(200, 255), random.randint(200, 255), random.randint(200, 255)))\n",
    "    elif captcha_type == \"bonus\":\n",
    "        if random.random() < 0.5:\n",
    "            image = Image.new(\"RGB\", (width, height), (255, 0, 0))\n",
    "            text = text[::-1]  \n",
    "        else:\n",
    "            image = Image.new(\"RGB\", (width, height), (0, 255, 0))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid captcha_type!\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    x = (width - text_length) // 2\n",
    "    y = (height - font_height) // 2\n",
    "    text_color = 'black' if captcha_type == 'easy' else (random.randint(0, 100), random.randint(0, 100), random.randint(0, 100))\n",
    "    draw.text((x, y), text=text, font=font, fill=text_color)\n",
    "    if captcha_type != \"easy\":\n",
    "        pixels = np.array(image)\n",
    "        noise = np.random.randint(0, 255, pixels.shape, dtype='uint8')\n",
    "        pixels = np.where(np.random.rand(*pixels.shape) < 0.05, noise, pixels)\n",
    "        image = Image.fromarray(pixels)\n",
    "        image = image.filter(ImageFilter.GaussianBlur(radius=0.5))\n",
    "    return image, text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08e7e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reads an image and applies binarization and noise removal.\n",
    "    References: \n",
    "        - /references/Pre-Processing in OCR!!!. A basic explanation of the most widely… _ by Susmith Reddy _ TDS Archive _ Medium.pdf\n",
    "        \n",
    "    Args:\n",
    "        image_path (str): Path to the input image. \n",
    "        \n",
    "    Returns:\"\n",
    "        np.ndarray: Preprocessed binary image.\n",
    "        \n",
    "    Converts the image to grayscale, applies Otsu's thresholding for binarization.\n",
    "    Denoising is performed using median blur with a kernel size of 3.\n",
    "    Morphological opening (erosion -> dilation) is applied to remove small noise particularly near character edges.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    denoised = cv2.medianBlur(binary, 3)\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    processed_img = cv2.morphologyEx(denoised, cv2.MORPH_OPEN, kernel)\n",
    "    return processed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1accd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_characters(binary_img: np.ndarray) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Segments the binary image using Vertical Histogram Projection.\n",
    "    References: \n",
    "        - /references/Pre-Processing in OCR!!!. A basic explanation of the most widely… _ by Susmith Reddy _ TDS Archive _ Medium.pdf\n",
    "        - /references/Segmentation in OCR !!. A basic explanation of different levels… _ by Susmith Reddy _ TDS Archive _ Medium.pdf\n",
    "        - /references/What is an OCR __. A basic theoretical overview of the… _ by Susmith Reddy _ TDS Archive _ Medium.pdf\n",
    "        \n",
    "    Args:\n",
    "        binary_img (np.ndarray): Preprocessed binary image.\n",
    "        \n",
    "    Returns:\n",
    "        List[np.ndarray]: List of segmented character images.\n",
    "        \n",
    "    Tries the following linear shear transformations to maximize a sharpness heuristic:\n",
    "    [[1, shear, 0],\n",
    "     [0,     1, 0]] \n",
    "    where shear values are from the following array:\n",
    "    array([-0.5 , -0.45, -0.4 , -0.35, -0.3 , -0.25, -0.2 , -0.15, -0.1 , -0.05,  0.  ,  0.05,  0.1 ,  0.15,  0.2 ,  0.25,  0.3 ,  0.35, 0.4 ,  0.45,  0.5 ])\n",
    "    In angular terms, this corresponds to shear angles from approximately -26.57 degrees to +26.57 degrees in 2.86 degree increments.\n",
    "    \n",
    "    Sharpness heuristic:\n",
    "        The sharpness score is defined as the sum of squared differences between consecutive histogram values.\n",
    "        The shear transformation that yields the highest sharpness score is selected for final segmentation.\n",
    "        \n",
    "    Nearest interpolation is used during the shear transformation to preserve binary values.\n",
    "    \n",
    "    After selecting the best shear, vertical histogram projection is performed on the sheared image to identify character boundaries.\n",
    "    At the moment, a column with zero pixel sum is used as a boundary between characters, however, more sophisticated methods like thresholding can be used in the future. \n",
    "    \"\"\"\n",
    "    h, w = binary_img.shape\n",
    "    best_shear = 0\n",
    "    max_score = -1\n",
    "    shear_range = np.linspace(-0.5, 0.5, 21) \n",
    "    for shear in shear_range:\n",
    "        M = np.float32([[1, shear, 0], [0, 1, 0]])\n",
    "        sheared_img = cv2.warpAffine(binary_img, M, (w, h), flags=cv2.INTER_NEAREST)\n",
    "        hist = np.sum(sheared_img, axis=0)\n",
    "        score = np.sum((hist[1:] - hist[:-1]) ** 2)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_shear = shear\n",
    "    pixel_sum_boundary_threshold = 0\n",
    "    M_best = np.float32([[1, best_shear, 0], [0, 1, 0]])\n",
    "    final_img = cv2.warpAffine(binary_img, M_best, (w, h), flags=cv2.INTER_NEAREST)\n",
    "    vertical_hist = np.sum(final_img, axis=0) / 255\n",
    "    segments = []\n",
    "    in_segment = False\n",
    "    start_col = 0\n",
    "    for col in range(w):\n",
    "        pixel_sum = vertical_hist[col]\n",
    "        if pixel_sum > 0 and not in_segment:\n",
    "            in_segment = True\n",
    "            start_col = col\n",
    "        elif pixel_sum == pixel_sum_boundary_threshold and in_segment:\n",
    "            in_segment = False\n",
    "            char_crop = final_img[:, start_col:col]\n",
    "            segments.append(char_crop)\n",
    "    if in_segment:\n",
    "        char_crop = final_img[:, start_col:w]\n",
    "        segments.append(char_crop)   \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc774bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_dataset(source_folder: str, output_folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Orchestrator function to process all images and save characters.\n",
    "    \n",
    "    Args:\n",
    "        source_folder (str): Folder containing source CAPTCHA images.\n",
    "        output_folder (str): Folder to save segmented character images.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "        \n",
    "    Orchestrates the preprocessing, segmentation, and saving of individual character images.\n",
    "    \"\"\"\n",
    "    mismatch_count = 0\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    files = [f for f in os.listdir(source_folder) if f.endswith('.png')]\n",
    "    print(f\"Processing {len(files)} images...\")\n",
    "    for filename in tqdm(files, desc=\"Processing images\"):\n",
    "        file_path = os.path.join(source_folder, filename)\n",
    "        ground_truth_text = os.path.splitext(filename)[0]\n",
    "        binary_img = preprocess_image(file_path)\n",
    "        if binary_img is None:\n",
    "            continue\n",
    "        char_imgs = segment_characters(binary_img)\n",
    "        if len(char_imgs) == len(ground_truth_text):\n",
    "            for i, char_img in enumerate(char_imgs):\n",
    "                char_label = ground_truth_text[i]\n",
    "                save_name = f\"{ground_truth_text}_{i}_{char_label}.png\"\n",
    "                os.makedirs(os.path.join(output_folder, f\"{char_label}\"), exist_ok=True)\n",
    "                save_path = os.path.join(output_folder, f\"{char_label}\", save_name)\n",
    "                cv2.imwrite(save_path, char_img)\n",
    "        else:\n",
    "            mismatch_count += 1\n",
    "    print(f\"Processing complete. {mismatch_count} mismatches found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa622667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "english_easy: 100%|██████████| 5000/5000 [13:46<00:00,  6.05it/s]\n",
      "english_hard: 100%|██████████| 5000/5000 [16:34<00:00,  5.03it/s]\n",
      "english_bonus: 100%|██████████| 2500/2500 [08:32<00:00,  4.88it/s]\n",
      "random_easy: 100%|██████████| 5000/5000 [00:24<00:00, 205.67it/s]\n",
      "random_hard: 100%|██████████| 5000/5000 [03:21<00:00, 24.86it/s]\n",
      "random_bonus: 100%|██████████| 2500/2500 [01:40<00:00, 24.98it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_dataset(\"data/generated/\", (10000, 10000, 5000), \"mixed_captcha\", 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "720d70ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8703 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 8703/8703 [01:04<00:00, 135.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. 909 mismatches found.\n",
      "Processing 8698 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 8698/8698 [00:49<00:00, 174.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. 563 mismatches found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_and_save_dataset('data/generated/hard/', 'data/processed/characters/')\n",
    "process_and_save_dataset('data/generated/easy/', 'data/processed/characters/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
