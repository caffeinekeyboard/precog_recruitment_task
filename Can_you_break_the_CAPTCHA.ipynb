{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bcdc473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from typing import Tuple, Literal, List\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
    "from wonderwords import RandomWord\n",
    "from tqdm.auto import tqdm\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13edc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_captcha(text, captcha_type: str = \"easy\", min_width: int = 512, height: int=224) -> Tuple[Image.Image, str]:\n",
    "    \"\"\"\n",
    "    Generates a text-based CAPTCHA image.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to be included in the CAPTCHA.\n",
    "        captcha_type (str): The type of CAPTCHA to generate (\"easy\", \"hard\", \"bonus\").\n",
    "        min_width (int): Minimum width of the CAPTCHA image.\n",
    "        height (int): Height of the CAPTCHA image.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[Image.Image, str]: A tuple containing the CAPTCHA image and the text.\n",
    "    \n",
    "    Easy CAPTCHA: Renders text in Arial font in the center of a white background. \n",
    "\n",
    "    Hard CAPTCHA: Renders text in a random font in the center of a random background, adds the following distortions:\n",
    "        - Random background color ((r, g, b) where each is differently in [200-255])\n",
    "        - Random font color ((r, g, b) where each is differently in [0-100])\n",
    "        - Random font size in [50%-70%] of image height\n",
    "        - 5% rainbow noise\n",
    "        - Gaussian blur with radius 0.5 pixels\n",
    "        \n",
    "    Bonus CAPTCHA: Renders text in a random font in the center of a random background, and follows the Hard CAPTCHA distortions in addition to:\n",
    "        - Randomly mirrors the text horizontally with 50% probability.\n",
    "        - If the text is mirrored, background color is red, else green.\n",
    "    \"\"\"\n",
    "    font_height = 156 if captcha_type == \"easy\" else (random.randint(int(0.5 * height), int(0.7 * height)))\n",
    "    font_face = \"fonts/arial.ttf\" if captcha_type == \"easy\" else \"fonts/\" + random.choice(os.listdir(\"fonts\")) \n",
    "    font = ImageFont.truetype(font_face, font_height)\n",
    "    text_length = font.getlength(text)\n",
    "    width = int(max(min_width, text_length + 80))\n",
    "    if captcha_type == \"easy\":\n",
    "        image = Image.new(\"RGB\", (width, height), (255, 255, 255))\n",
    "    elif captcha_type == \"hard\":\n",
    "        image = Image.new(\"RGB\", (width, height),(random.randint(200, 255), random.randint(200, 255), random.randint(200, 255)))\n",
    "    elif captcha_type == \"bonus\":\n",
    "        if random.random() < 0.5:\n",
    "            image = Image.new(\"RGB\", (width, height), (255, 0, 0))\n",
    "            text = text[::-1]  \n",
    "        else:\n",
    "            image = Image.new(\"RGB\", (width, height), (0, 255, 0))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid captcha_type!\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    x = (width - text_length) // 2\n",
    "    y = (height - font_height) // 2\n",
    "    text_color = 'black' if captcha_type == 'easy' else (random.randint(0, 100), random.randint(0, 100), random.randint(0, 100))\n",
    "    draw.text((x, y), text=text, font=font, fill=text_color)\n",
    "    if captcha_type != \"easy\":\n",
    "        pixels = np.array(image)\n",
    "        noise = np.random.randint(0, 255, pixels.shape, dtype='uint8')\n",
    "        pixels = np.where(np.random.rand(*pixels.shape) < 0.05, noise, pixels)\n",
    "        image = Image.fromarray(pixels)\n",
    "        image = image.filter(ImageFilter.GaussianBlur(radius=0.5))\n",
    "    return image, text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2af1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(\n",
    "    path: str = \"data/generated/\", \n",
    "    num_samples: Tuple[int, int, int] = (1000, 1000, 500), \n",
    "    word_type: Literal[\"english_captcha\", \"random_captcha\", \"mixed_captcha\"] = \"english_captcha\",\n",
    "    mix_ratio: float = 0.5\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "    Generates a dataset of CAPTCHA images and saves them to disk.\n",
    "    \n",
    "    Args:\n",
    "        path (str): Directory to save the generated CAPTCHA images.\n",
    "        num_samples (Tuple[int, int, int]): Number of samples for each CAPTCHA type (easy, hard, bonus).\n",
    "        word_type (Literal): Type of words to use in CAPTCHAs (\"english_captcha\", \"random_captcha\", \"mixed_captcha\").\n",
    "        mix_ratio (float): Ratio of english to random words if word_type is \"mixed_captcha\".\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "        \n",
    "    Creates or adds samples to the specified directory with the following subdirectories:\n",
    "        - easy/\n",
    "        - hard/\n",
    "        - bonus/\n",
    "        \n",
    "    Word types:\n",
    "        - english_captcha: Uses a random word from \n",
    "    \"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    os.makedirs(os.path.join(path, \"easy\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(path, \"hard\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(path, \"bonus\"), exist_ok=True)\n",
    "    english_captcha_samples = (0, 0, 0)\n",
    "    random_capcha_samples = (0, 0, 0)\n",
    "    if word_type == \"english_captcha\":\n",
    "        english_captcha_samples = num_samples\n",
    "    elif word_type == \"random_captcha\":\n",
    "        random_capcha_samples = num_samples\n",
    "    elif word_type == \"mixed_captcha\":\n",
    "        english_captcha_samples = (int(num_samples[0] * mix_ratio), int(num_samples[1] * mix_ratio), int(num_samples[2] * mix_ratio))\n",
    "        random_capcha_samples = (num_samples[0] - english_captcha_samples[0],\n",
    "                                 num_samples[1] - english_captcha_samples[1],\n",
    "                                 num_samples[2] - english_captcha_samples[2])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid word_type!\")\n",
    "    for i in tqdm(range(english_captcha_samples[0]), desc=\"english_easy\"):\n",
    "        word = RandomWord().word()\n",
    "        image, text = generate_text_captcha(word, captcha_type=\"easy\")\n",
    "        image.save(os.path.join(path, \"easy\", f\"{text}.png\"))\n",
    "    for i in tqdm(range(english_captcha_samples[1]), desc=\"english_hard\"):\n",
    "        word = RandomWord().word()\n",
    "        image, text = generate_text_captcha(word, captcha_type=\"hard\")\n",
    "        image.save(os.path.join(path, \"hard\", f\"{text}.png\"))\n",
    "    for i in tqdm(range(english_captcha_samples[2]), desc=\"english_bonus\"):\n",
    "        word = RandomWord().word()\n",
    "        image, text = generate_text_captcha(word, captcha_type=\"bonus\")\n",
    "        image.save(os.path.join(path, \"bonus\", f\"{text}.png\")) \n",
    "    def get_random_string(min_len=4, max_len=8):\n",
    "        chars = string.ascii_uppercase + string.digits\n",
    "        return ''.join(random.choices(chars, k=random.randint(min_len, max_len)))\n",
    "    for i in tqdm(range(random_capcha_samples[0]), desc=\"random_easy\"):\n",
    "        word = get_random_string()\n",
    "        image, text = generate_text_captcha(word, captcha_type=\"easy\")\n",
    "        image.save(os.path.join(path, \"easy\", f\"{text}.png\"))\n",
    "    for i in tqdm(range(random_capcha_samples[1]), desc=\"random_hard\"):\n",
    "        word = get_random_string()\n",
    "        image, text = generate_text_captcha(word, captcha_type=\"hard\")\n",
    "        image.save(os.path.join(path, \"hard\", f\"{text}.png\"))\n",
    "    for i in tqdm(range(random_capcha_samples[2]), desc=\"random_bonus\"):\n",
    "        word = get_random_string()\n",
    "        image, text = generate_text_captcha(word, captcha_type=\"bonus\")\n",
    "        image.save(os.path.join(path, \"bonus\", f\"{text}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08e7e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reads an image and applies binarization and noise removal.\n",
    "    References: \n",
    "        - /references/Pre-Processing in OCR!!!. A basic explanation of the most widely… _ by Susmith Reddy _ TDS Archive _ Medium.pdf\n",
    "        \n",
    "    Args:\n",
    "        image_path (str): Path to the input image. \n",
    "        \n",
    "    Returns:\"\n",
    "        np.ndarray: Preprocessed binary image.\n",
    "        \n",
    "    Converts the image to grayscale, applies Otsu's thresholding for binarization.\n",
    "    Denoising is performed using median blur with a kernel size of 3.\n",
    "    Morphological opening (erosion -> dilation) is applied to remove small noise particularly near character edges.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    denoised = cv2.medianBlur(binary, 3)\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    processed_img = cv2.morphologyEx(denoised, cv2.MORPH_OPEN, kernel)\n",
    "    return processed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1accd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_characters(binary_img: np.ndarray) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Segments the binary image using Vertical Histogram Projection.\n",
    "    References: \n",
    "        - /references/Pre-Processing in OCR!!!. A basic explanation of the most widely… _ by Susmith Reddy _ TDS Archive _ Medium.pdf\n",
    "        - /references/Segmentation in OCR !!. A basic explanation of different levels… _ by Susmith Reddy _ TDS Archive _ Medium.pdf\n",
    "        - /references/What is an OCR __. A basic theoretical overview of the… _ by Susmith Reddy _ TDS Archive _ Medium.pdf\n",
    "        \n",
    "    Args:\n",
    "        binary_img (np.ndarray): Preprocessed binary image.\n",
    "        \n",
    "    Returns:\n",
    "        List[np.ndarray]: List of segmented character images.\n",
    "        \n",
    "    Tries the following linear shear transformations to maximize a sharpness heuristic:\n",
    "    [[1, shear, 0],\n",
    "     [0,     1, 0]] \n",
    "    where shear values are from the following array:\n",
    "    array([-0.5 , -0.45, -0.4 , -0.35, -0.3 , -0.25, -0.2 , -0.15, -0.1 , -0.05,  0.  ,  0.05,  0.1 ,  0.15,  0.2 ,  0.25,  0.3 ,  0.35, 0.4 ,  0.45,  0.5 ])\n",
    "    In angular terms, this corresponds to shear angles from approximately -26.57 degrees to +26.57 degrees in 2.86 degree increments.\n",
    "    \n",
    "    Sharpness heuristic:\n",
    "        The sharpness score is defined as the sum of squared differences between consecutive histogram values.\n",
    "        The shear transformation that yields the highest sharpness score is selected for final segmentation.\n",
    "        \n",
    "    Nearest interpolation is used during the shear transformation to preserve binary values.\n",
    "    \n",
    "    After selecting the best shear, vertical histogram projection is performed on the sheared image to identify character boundaries.\n",
    "    At the moment, a column with zero pixel sum is used as a boundary between characters, however, more sophisticated methods like thresholding can be used in the future. \n",
    "    \"\"\"\n",
    "    h, w = binary_img.shape\n",
    "    best_shear = 0\n",
    "    max_score = -1\n",
    "    shear_range = np.linspace(-0.5, 0.5, 21) \n",
    "    for shear in shear_range:\n",
    "        M = np.float32([[1, shear, 0], [0, 1, 0]])\n",
    "        sheared_img = cv2.warpAffine(binary_img, M, (w, h), flags=cv2.INTER_NEAREST)\n",
    "        hist = np.sum(sheared_img, axis=0)\n",
    "        score = np.sum((hist[1:] - hist[:-1]) ** 2)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_shear = shear\n",
    "    pixel_sum_boundary_threshold = 0\n",
    "    M_best = np.float32([[1, best_shear, 0], [0, 1, 0]])\n",
    "    final_img = cv2.warpAffine(binary_img, M_best, (w, h), flags=cv2.INTER_NEAREST)\n",
    "    vertical_hist = np.sum(final_img, axis=0) / 255\n",
    "    segments = []\n",
    "    in_segment = False\n",
    "    start_col = 0\n",
    "    for col in range(w):\n",
    "        pixel_sum = vertical_hist[col]\n",
    "        if pixel_sum > 0 and not in_segment:\n",
    "            in_segment = True\n",
    "            start_col = col\n",
    "        elif pixel_sum == pixel_sum_boundary_threshold and in_segment:\n",
    "            in_segment = False\n",
    "            char_crop = final_img[:, start_col:col]\n",
    "            segments.append(char_crop)\n",
    "    if in_segment:\n",
    "        char_crop = final_img[:, start_col:w]\n",
    "        segments.append(char_crop)   \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc774bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_dataset(source_folder: str, output_folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Orchestrator function to process all images and save characters.\n",
    "    \n",
    "    Args:\n",
    "        source_folder (str): Folder containing source CAPTCHA images.\n",
    "        output_folder (str): Folder to save segmented character images.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "        \n",
    "    Orchestrates the preprocessing, segmentation, and saving of individual character images.\n",
    "    \"\"\"\n",
    "    mismatch_count = 0\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    files = [f for f in os.listdir(source_folder) if f.endswith('.png')]\n",
    "    print(f\"Processing {len(files)} images...\")\n",
    "    for filename in tqdm(files, desc=\"Processing images\"):\n",
    "        file_path = os.path.join(source_folder, filename)\n",
    "        ground_truth_text = os.path.splitext(filename)[0]\n",
    "        binary_img = preprocess_image(file_path)\n",
    "        if binary_img is None:\n",
    "            continue\n",
    "        char_imgs = segment_characters(binary_img)\n",
    "        if len(char_imgs) == len(ground_truth_text):\n",
    "            for i, char_img in enumerate(char_imgs):\n",
    "                char_label = ground_truth_text[i]\n",
    "                save_name = f\"{ground_truth_text}_{i}_{char_label}.png\"\n",
    "                os.makedirs(os.path.join(output_folder, f\"{char_label}\"), exist_ok=True)\n",
    "                save_path = os.path.join(output_folder, f\"{char_label}\", save_name)\n",
    "                cv2.imwrite(save_path, char_img)\n",
    "        else:\n",
    "            mismatch_count += 1\n",
    "    print(f\"Processing complete. {mismatch_count} mismatches found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa622667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "english_easy: 100%|██████████| 5000/5000 [13:46<00:00,  6.05it/s]\n",
      "english_hard: 100%|██████████| 5000/5000 [16:34<00:00,  5.03it/s]\n",
      "english_bonus: 100%|██████████| 2500/2500 [08:32<00:00,  4.88it/s]\n",
      "random_easy: 100%|██████████| 5000/5000 [00:24<00:00, 205.67it/s]\n",
      "random_hard: 100%|██████████| 5000/5000 [03:21<00:00, 24.86it/s]\n",
      "random_bonus: 100%|██████████| 2500/2500 [01:40<00:00, 24.98it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_dataset(\"data/generated/\", (10000, 10000, 5000), \"mixed_captcha\", 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "720d70ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8703 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 8703/8703 [01:02<00:00, 139.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. 909 mismatches found.\n",
      "Processing 8698 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 8698/8698 [00:48<00:00, 177.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. 563 mismatches found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_and_save_dataset('data/generated/hard/', 'data/processed/characters/')\n",
    "process_and_save_dataset('data/generated/easy/', 'data/processed/characters/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e39d729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "CharNet                                  [1, 1, 32, 32]            [1, 62]                   --\n",
       "├─Sequential: 1-1                        [1, 1, 32, 32]            [1, 32, 16, 16]           --\n",
       "│    └─Conv2d: 2-1                       [1, 1, 32, 32]            [1, 32, 32, 32]           320\n",
       "│    └─BatchNorm2d: 2-2                  [1, 32, 32, 32]           [1, 32, 32, 32]           64\n",
       "│    └─ReLU: 2-3                         [1, 32, 32, 32]           [1, 32, 32, 32]           --\n",
       "│    └─MaxPool2d: 2-4                    [1, 32, 32, 32]           [1, 32, 16, 16]           --\n",
       "├─Sequential: 1-2                        [1, 32, 16, 16]           [1, 64, 8, 8]             --\n",
       "│    └─Conv2d: 2-5                       [1, 32, 16, 16]           [1, 64, 16, 16]           18,496\n",
       "│    └─BatchNorm2d: 2-6                  [1, 64, 16, 16]           [1, 64, 16, 16]           128\n",
       "│    └─ReLU: 2-7                         [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
       "│    └─MaxPool2d: 2-8                    [1, 64, 16, 16]           [1, 64, 8, 8]             --\n",
       "├─Sequential: 1-3                        [1, 64, 8, 8]             [1, 128, 4, 4]            --\n",
       "│    └─Conv2d: 2-9                       [1, 64, 8, 8]             [1, 128, 8, 8]            73,856\n",
       "│    └─BatchNorm2d: 2-10                 [1, 128, 8, 8]            [1, 128, 8, 8]            256\n",
       "│    └─ReLU: 2-11                        [1, 128, 8, 8]            [1, 128, 8, 8]            --\n",
       "│    └─MaxPool2d: 2-12                   [1, 128, 8, 8]            [1, 128, 4, 4]            --\n",
       "├─Sequential: 1-4                        [1, 128, 4, 4]            [1, 62]                   --\n",
       "│    └─Flatten: 2-13                     [1, 128, 4, 4]            [1, 2048]                 --\n",
       "│    └─Linear: 2-14                      [1, 2048]                 [1, 512]                  1,049,088\n",
       "│    └─ReLU: 2-15                        [1, 512]                  [1, 512]                  --\n",
       "│    └─Dropout: 2-16                     [1, 512]                  [1, 512]                  --\n",
       "│    └─Linear: 2-17                      [1, 512]                  [1, 62]                   31,806\n",
       "===================================================================================================================\n",
       "Total params: 1,174,014\n",
       "Trainable params: 1,174,014\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 10.87\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.92\n",
       "Params size (MB): 4.70\n",
       "Estimated Total Size (MB): 5.62\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CharNet(nn.Module):\n",
    "    \"\"\"\n",
    "    VGG-Style CNN model for character recognition - 1.17M.\n",
    "    \n",
    "    Total params: 1,174,014\n",
    "    Trainable params: 1,174,014\n",
    "    Non-trainable params: 0\n",
    "    \n",
    "    The following tensor dimension trace will be there assuming a 32 x 32 image:\n",
    "    \n",
    "    INPUT       -                   B  x    1  x  32  x  32\n",
    "    BLOCK 1     Conv + Pool         B  x   32  x  16  x  16\n",
    "    BLOCK 2     Conv + Pool         B  x   64  x   8  x   8\n",
    "    BLOCK 3     Conv + Pool         B  x  128  x   4  x   4\n",
    "    FLATTEN     Reshape             B  x 2048\n",
    "    CLASSIIFIER Linear              B  x  512\n",
    "    OUTPUT      Linear              B  x   62\n",
    "    \n",
    "    Block 1:\n",
    "        - Conv2d: 1 -> 32, 3x3 kernel, padding 1.\n",
    "        - BatchNorm2d.\n",
    "        - ReLU.\n",
    "        - MaxPool2d: 2x2 kernel, stride 2.\n",
    "\n",
    "    Block 2:\n",
    "        - Conv2d: 32 -> 64, 3x3 kernel, padding 1.\n",
    "        - BatchNorm2d.\n",
    "        - ReLU.\n",
    "        - MaxPool2d: 2x2 kernel, stride 2.\n",
    "\n",
    "    Block 3:\n",
    "        - Conv2d: 64 -> 128, 3x3 kernel, padding 1.\n",
    "        - BatchNorm2d.\n",
    "        - ReLU.\n",
    "        - MaxPool2d: 2x2 kernel, stride 2.\n",
    "\n",
    "    Classifier:\n",
    "        - Flatten: Reshape (B, 128, H/8, W/8) to (B, Features).\n",
    "        - LazyLinear: Features -> 512 .\n",
    "        - ReLU: Activation.\n",
    "        - Dropout: Drops 50% of neurons.\n",
    "        - Linear: 512 -> num_classes.\n",
    "\n",
    "    Args:\n",
    "        input_size (int): Expected height/width of square input image (default 32).\n",
    "        num_classes (int): Number of output classes (default 62).\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int = 32, num_classes: int = 62):\n",
    "        super(CharNet, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = CharNet(input_size=32, num_classes=62)\n",
    "summary(model, input_size=(1, 1, 32, 32), col_names=[\"input_size\", \"output_size\", \"num_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a53e5bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 91568\n",
      "Classes found: 62\n",
      "Class to Index Mapping (first 15): [('0', 0), ('1', 1), ('2', 2), ('3', 3), ('4', 4), ('5', 5), ('6', 6), ('7', 7), ('8', 8), ('9', 9), ('A', 10), ('B', 11), ('C', 12), ('D', 13), ('E', 14), ('F', 15), ('G', 16), ('H', 17), ('I', 18), ('J', 19), ('K', 20), ('L', 21), ('M', 22), ('N', 23), ('O', 24), ('P', 25), ('Q', 26), ('R', 27), ('S', 28), ('T', 29), ('U', 30), ('V', 31), ('W', 32), ('X', 33), ('Y', 34), ('Z', 35), ('a', 36), ('b', 37), ('c', 38), ('d', 39), ('e', 40), ('f', 41), ('g', 42), ('h', 43), ('i', 44), ('j', 45), ('k', 46), ('l', 47), ('m', 48), ('n', 49), ('o', 50), ('p', 51), ('q', 52), ('r', 53), ('s', 54), ('t', 55), ('u', 56), ('v', 57), ('w', 58), ('x', 59), ('y', 60), ('z', 61)]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "data_path = \"data/processed/characters\"\n",
    "full_dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "print(f\"Total images found: {len(full_dataset)}\")\n",
    "print(f\"Classes found: {len(full_dataset.classes)}\")\n",
    "print(f\"Class to Index Mapping (first 15): {list(full_dataset.class_to_idx.items())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84f5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 73254\n",
      "Validation set size: 18314\n",
      "\n",
      "--- Batch Verification ---\n",
      "Image Batch Shape: torch.Size([64, 1, 32, 32])\n",
      "Label Batch Shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "print(\"\\n--- Batch Verification ---\")\n",
    "print(f\"Image Batch Shape: {images.shape}\")   # Should be 64 x 1 x 32 x 32\n",
    "print(f\"Label Batch Shape: {labels.shape}\")   # Should be 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b1c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
